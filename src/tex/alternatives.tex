\section{Alternatives}
\subsection{Faster R-CNN (Region-Based Convolutional Neural Network)}
Faster R-CNN works by using selective search to extract regions of interest in a picture, and then resizes these regions to a specific size, and runs these sub-images through a trained neural network to see if a known object can be found on any of them \cite[sec.~2]{rcnn}.

\begin{minted}{python}
def get_prediction(self, img, transform):
	img = transform(img)
	pred = self.model([img])
	return pred[0]
\end{minted}

\subsection{YOLO (You only look once)}
What makes YOLO different from other algorithms in that it is only passed through a neural network once, and then the result is processed by a non-max suppression algorithm that makes sure the same object hasn't been found multiple times \cite{yolo}.

\begin{minted}{python}
def get_prediction(self, img):
	bboxs, labels, confs = cv.detect_common_objects(img)
    return bboxs, labels, confs
\end{minted}

\subsection{HOG (Histogram of oriented gradients)}
HOG is used in computer vision, as a feature descriptor for object detection. First a gradient orientation is calculated for small areas of the image, then HOG is able to extract features from the gradient orientation data, this is done by HOG being able to detect  edges and the direction of the edges \cite{hog}.

\begin{minted}{python}
def get_prediction(self, image):
	if image.shape[1] < 400:
		(height, width) = image.shape[:2]
		ratio = width / float(width)
		image = cv2.resize(image, (400, width * ratio))
	img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
	rects, weights = self.hog.detectMultiScale(img_gray,
					 winStride=(2, 2),
					 padding=(10, 10),
					 scale=1.02)
	return rects, weights
\end{minted}
